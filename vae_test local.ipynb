{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPi3zOPJtIza"
      },
      "source": [
        "**Apogee Data Simple VAE Testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Nov 19 12:07:04 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 496.49       Driver Version: 496.49       CUDA Version: 11.5     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ... WDDM  | 00000000:0A:00.0  On |                  N/A |\n",
            "|  0%   47C    P8    27W / 340W |   1569MiB / 10240MiB |      1%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A       904    C+G   ...020.53\\msedgewebview2.exe    N/A      |\n",
            "|    0   N/A  N/A      1132    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
            "|    0   N/A  N/A      1532    C+G   ...Roaming\\Zoom\\bin\\Zoom.exe    N/A      |\n",
            "|    0   N/A  N/A      2080    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
            "|    0   N/A  N/A      3044    C+G   Insufficient Permissions        N/A      |\n",
            "|    0   N/A  N/A      5240    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
            "|    0   N/A  N/A      5252    C+G   Insufficient Permissions        N/A      |\n",
            "|    0   N/A  N/A      5948    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
            "|    0   N/A  N/A      8764    C+G   ...b3d8bbwe\\WinStore.App.exe    N/A      |\n",
            "|    0   N/A  N/A     10236    C+G   ...zilla Firefox\\firefox.exe    N/A      |\n",
            "|    0   N/A  N/A     12480    C+G   ...ekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
            "|    0   N/A  N/A     14080    C+G   ...ram Files\\LGHUB\\lghub.exe    N/A      |\n",
            "|    0   N/A  N/A     14264    C+G   Insufficient Permissions        N/A      |\n",
            "|    0   N/A  N/A     14804    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A     15304    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     15640    C+G   ...zpdnekdrzrea0\\Spotify.exe    N/A      |\n",
            "|    0   N/A  N/A     16176    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
            "|    0   N/A  N/A     16988    C+G   ...\\app-1.0.9003\\Discord.exe    N/A      |\n",
            "|    0   N/A  N/A     17508    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
            "|    0   N/A  N/A     17616    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A     19492    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     20740    C+G   ...zilla Firefox\\firefox.exe    N/A      |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Hardware check\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Kt-ZMAZGmU1u"
      },
      "outputs": [],
      "source": [
        "# Basic imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torch.optim import Adam\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torchvision.utils import save_image, make_grid\n",
        "\n",
        "from astropy.io import fits\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "0\n",
            "<torch.cuda.device object at 0x000001DD71FBCF40>\n",
            "1\n",
            "NVIDIA GeForce RTX 3080\n"
          ]
        }
      ],
      "source": [
        "# GPU verification\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.current_device())\n",
        "print(torch.cuda.device(0))\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KNbKYArtDJN"
      },
      "source": [
        "**Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FSJ0N0cTo2yA"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "dataset_path = '~/datasets'\n",
        "cuda = True\n",
        "DEVICE = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "\n",
        "# Data parameters\n",
        "input_rows = 100   # Number of spectra to input\n",
        "batch_size = 5\n",
        "validation_split = .2   # Fraction of dataset to reserve for test\n",
        "random_seed = 42\n",
        "np.random.seed(random_seed)\n",
        "shuffle_toggle = True\n",
        "\n",
        "# Model Dimensions\n",
        "x_dim  = 7514\n",
        "hidden_dim = 400\n",
        "latent_dim = 200\n",
        "\n",
        "# Learning rate\n",
        "# Default 0.001\n",
        "lr = 0.01\n",
        "\n",
        "# Num epochs\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Y2UrIArFBs"
      },
      "source": [
        "**Process and Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dTbI8VPmxIXi"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WljSeTcCxmus"
      },
      "outputs": [],
      "source": [
        "def starInfoDebug():\n",
        "  for i in range(10):\n",
        "      # Title information\n",
        "      print(\"\\n**************** Looking at index \", i, \" ****************\")\n",
        "      print(\"APSTAR ID: \", star['apstar_id'][i],\\\n",
        "          \"\\nTARGET_ID: \", star['target_id'][i],\\\n",
        "              \"\\nASPCAP_ID: \", star['aspcap_id'][i])\n",
        "      \n",
        "      print(\"\\nBasic Stats:\")\n",
        "      print(\"SNR: \", star['snr'][i])\n",
        "      print(\"Effective Temp (K) \\t ASPCAP: \", star['teff_spec'][i], 'AstroNN:', star_astroNN['TEFF'][i])\n",
        "      print(\"Surface G (log(cm/s^2) \\t ASPCAP: \", star['logg_spec'][i], 'AstroNN:', star_astroNN['LOGG'][i])\n",
        "\n",
        "      #j = ind[i]\n",
        "      j = i\n",
        "\n",
        "      plt.subplot(5, 2, j+1)\n",
        "      plt.title(star['aspcap_id'][i])\n",
        "      plt.xlabel('Wavelength')\n",
        "      plt.ylabel('Relative Flux')\n",
        "      # 7514 data points for each spectra\n",
        "      plt.plot(star_spectra[j])\n",
        "\n",
        "      spectra_df = pd.DataFrame(star_spectra[j])\n",
        "      # Actual input data\n",
        "      print(\"\\nInput dataframe:\")\n",
        "      print(spectra_df)\n",
        "\n",
        "      #print(len(star_spectra[j]))\n",
        "      #plt.legend([star['aspcap_id'][i]])\n",
        "      #plt.show()\n",
        "\n",
        "      # Abundances, other info\n",
        "      print(\"\\nAbundances, additional info (ASPCAP):\")\n",
        "      print(star['ra'][j], star['dec'][j], star['glon'][j], star['glat'][j],\\\n",
        "          star['vhelio_avg'][j], star['vscatter'][j],\\\n",
        "          star['teff'][j], star['teff_err'][j],\\\n",
        "          star['logg'][j], star['logg_err'][j],\\\n",
        "          star['m_h'][j], star['m_h_err'][j],\\\n",
        "          star['alpha_m'][j], star['alpha_m_err'][j],\\\n",
        "          star['c_fe'][j], star['c_fe_err'][j],\\\n",
        "          star['cI_fe'][j], star['cI_fe_err'][j],\\\n",
        "          star['n_fe'][j], star['n_fe_err'][j],\\\n",
        "          star['o_fe'][j], star['o_fe_err'][j],\\\n",
        "          star['na_fe'][j], star['na_fe_err'][j],\\\n",
        "          star['mg_fe'][j], star['mg_fe_err'][j],\\\n",
        "          star['al_fe'][j], star['al_fe_err'][j],\\\n",
        "          star['si_fe'][j], star['si_fe_err'][j],\\\n",
        "          star['p_fe'][j], star['p_fe_err'][j],\\\n",
        "          star['s_fe'][j], star['s_fe_err'][j],\\\n",
        "          star['k_fe'][j], star['k_fe_err'][j],\\\n",
        "          star['ca_fe'][j], star['ca_fe_err'][j],\\\n",
        "          star['ti_fe'][j], star['ti_fe_err'][j],\\\n",
        "          star['v_fe'][j], star['v_fe_err'][j],\\\n",
        "          star['cr_fe'][j], star['cr_fe_err'][j],\\\n",
        "          star['mn_fe'][j], star['mn_fe_err'][j],\\\n",
        "          star['fe_h'][j], star['fe_h_err'][j],\\\n",
        "          star['co_fe'][j], star['co_fe_err'][j],\\\n",
        "          star['ni_fe'][j], star['ni_fe_err'][j],\\\n",
        "          star['cu_fe'][j], star['cu_fe_err'][j],\\\n",
        "          star['ge_fe'][j], star['ge_fe_err'][j],\\\n",
        "          star['rb_fe'][j], star['rb_fe_err'][j],\\\n",
        "          star['aspcapflags'][j], star['starflags'][j])\n",
        "\n",
        "      plt.subplots_adjust(hspace=1)\n",
        "      #plt.tight_layout()\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tI_JwkURxMB0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " ********************** Opening FITS files from drive **********************\n",
            "Number of spectra:  473307\n",
            "Data points per spectra:  7514\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n ********************** Opening FITS files from drive **********************\")\n",
        "\n",
        "star_hdus = fits.open('allStar-r12-l33.fits')\n",
        "astroNN_hdus = fits.open('apogee_astroNN-DR16-v1.fits')\n",
        "star_spec = fits.open('contspec_dr16_final.fits')\n",
        "\n",
        "star = star_hdus[1].data\n",
        "star_astroNN = astroNN_hdus[1].data\n",
        "star_spectra = star_spec[0].data\n",
        "\n",
        "star_hdus.close()\n",
        "astroNN_hdus.close()\n",
        "star_spec.close()\n",
        "\n",
        "print(\"Number of spectra: \", len(star))\n",
        "print(\"Data points per spectra: \", len(star_spectra[1]))\n",
        "\n",
        "# starInfoDebug()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDGazuZYICa1"
      },
      "source": [
        "**Dataset Class for Spectral data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rI2XwUlO5wqQ"
      },
      "outputs": [],
      "source": [
        "# https://visualstudiomagazine.com/articles/2020/09/10/pytorch-dataloader.aspx\n",
        "\n",
        "class spectraDataset(torch.utils.data.Dataset):\n",
        "\n",
        "  # Num rows = max number of spectra to load\n",
        "  def __init__(self, src, num_rows=None):\n",
        "    if num_rows == None:\n",
        "      spectra = src.astype(np.float32)\n",
        "    else:\n",
        "      spectra = src.astype(np.float32)[0:num_rows]\n",
        "\n",
        "    # y_tmp = np.loadtxt(src_file, max_rows=num_rows,\n",
        "    #   usecols=7, delimiter=\"\\t\", skiprows=0,\n",
        "    #   dtype=np.long)\n",
        "\n",
        "    self.x_data = torch.tensor(spectra, dtype=torch.float32)\n",
        "\n",
        "    # self.y_data = T.tensor(y_tmp,\n",
        "    #   dtype=T.long).to(DEVICE)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x_data)  # required\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # if T.is_tensor(idx):\n",
        "    #   idx = idx.tolist()\n",
        "    # preds = self.x_data[idx, 0:7]\n",
        "    # pol = self.y_data[idx]\n",
        "    # sample = \\\n",
        "    #   { 'predictors' : preds, 'political' : pol }\n",
        "\n",
        "    sample = self.x_data[idx]\n",
        "    return sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOkDqqAoH_ou"
      },
      "source": [
        "**Train/Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kGYcFC8BKLcD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        0         1         2         3         4         5         6     \\\n",
            "0   1.029298  1.019125  1.030769  1.047487  1.039964  1.028696  1.041467   \n",
            "1   0.990036  0.987269  0.994762  1.014196  1.023387  1.023809  1.032977   \n",
            "2   0.966026  0.802236  1.219610  1.310636  0.885086  0.855891  0.941577   \n",
            "3   0.925234  0.952573  0.947935  0.971894  1.015564  1.048688  1.049001   \n",
            "4   0.878808  0.904151  0.959540  1.010035  1.040815  1.054573  1.059369   \n",
            "..       ...       ...       ...       ...       ...       ...       ...   \n",
            "95  0.995711  0.993701  0.997927  1.012820  1.036780  1.026134  0.996898   \n",
            "96  1.021801  1.025004  1.022827  1.022189  1.028265  1.026983  1.016742   \n",
            "97  0.926257  0.961581  0.946531  0.950532  1.018308  1.022714  0.970963   \n",
            "98  0.994511  1.015827  1.018948  1.008733  1.023380  1.045009  1.036289   \n",
            "99  1.007633  1.008484  1.012747  1.024576  1.032456  1.025861  1.022419   \n",
            "\n",
            "        7         8         9     ...      7504      7505      7506      7507  \\\n",
            "0   1.044751  1.034174  1.041306  ...  0.995729  1.100086  1.029313  0.959485   \n",
            "1   1.038611  1.031156  1.024400  ...  0.949991  0.933548  0.964648  0.964543   \n",
            "2   0.776780  0.918720  1.191249  ...  1.083606  3.089595  2.144881  0.888401   \n",
            "3   1.024613  1.018155  1.028265  ...  0.955415  0.934431  0.927043  0.964045   \n",
            "4   1.058488  1.053649  1.048092  ...  0.917104  0.937378  0.947413  0.958011   \n",
            "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
            "95  1.011702  1.022309  0.999052  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "96  1.015491  1.022017  1.021894  ...  0.986946  0.987841  1.000548  0.992288   \n",
            "97  0.979797  1.001511  0.979549  ...  0.934681  0.931677  0.871578  0.934781   \n",
            "98  1.017613  1.014889  1.017061  ...  0.936900  0.946436  0.961853  0.925238   \n",
            "99  1.023211  1.017796  1.018746  ...  1.197181  0.885450  1.032200  0.975725   \n",
            "\n",
            "        7508      7509      7510      7511      7512      7513  \n",
            "0   1.041395  0.991530  1.023653  0.971355  0.948459  0.951225  \n",
            "1   0.972279  0.972806  0.962122  0.961664  0.965745  0.952771  \n",
            "2   0.652072  0.806873  1.000000  1.000000  1.000000  1.000000  \n",
            "3   1.012850  0.973799  0.964529  1.019993  0.954958  0.952475  \n",
            "4   0.971418  0.981196  0.991603  1.001394  0.994144  0.976024  \n",
            "..       ...       ...       ...       ...       ...       ...  \n",
            "95  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "96  0.989482  0.990524  0.988023  0.994439  0.979352  0.972735  \n",
            "97  0.952458  0.936588  0.978027  0.950024  0.986711  0.994244  \n",
            "98  0.942764  0.932937  0.928860  0.985324  0.986488  0.975607  \n",
            "99  0.984767  0.985634  1.012325  1.027906  0.968639  0.995501  \n",
            "\n",
            "[100 rows x 7514 columns]\n"
          ]
        }
      ],
      "source": [
        "# # Reduce the dataset down to a manageable size, based on input_rows hyperparameter\n",
        "np.random.seed(42)\n",
        "random_reduced_idx = list(np.random.choice(len(star_spectra), input_rows, replace=False))\n",
        "\n",
        "# # Grab only spectra with indices randomly selected from above\n",
        "#reduced_star_spectra = np.take(star_spectra, random_reduced_idx, 0)\n",
        "reduced_star_spectra = star_spectra[random_reduced_idx]\n",
        "print(pd.DataFrame(reduced_star_spectra))\n",
        "\n",
        "\n",
        "#Basic subset testing\n",
        "#reduced_star_spectra = star_spectra[0:input_rows]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bfJHX-yFpdiK"
      },
      "outputs": [],
      "source": [
        "#Normalize (between 0 and 1)\n",
        "\n",
        "# sum_of_rows = reduced_star_spectra.sum(axis=1)\n",
        "# reduced_star_spectra = reduced_star_spectra / sum_of_rows[:, np.newaxis]\n",
        "\n",
        "# reduced_maximum = np.amax(reduced_star_spectra)\n",
        "# print(reduced_maximum)\n",
        "# reduced_star_spectra = reduced_star_spectra/reduced_maximum\n",
        "\n",
        "# Normalization array\n",
        "# reduced_maximum = np.zeros(len(reduced_star_spectra))\n",
        "\n",
        "# for i in range(0, len(reduced_star_spectra)):\n",
        "#   reduced_maximum[i] = np.amax(reduced_star_spectra[i])\n",
        "#   reduced_star_spectra[i] = reduced_star_spectra[i]/reduced_maximum[i]\n",
        "\n",
        "# print(pd.DataFrame(reduced_star_spectra))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cC-aEHs9pV4e"
      },
      "outputs": [],
      "source": [
        "# Final normalized, reduced inputs\n",
        "train_dataset = spectraDataset(reduced_star_spectra)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xnK9JzFyH_O_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Splitting dataset at 20\n"
          ]
        }
      ],
      "source": [
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(reduced_star_spectra)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "\n",
        "print(\"Splitting dataset at\", split)\n",
        "\n",
        "# If shuffling is enabled, use random seed to shuffle data indices\n",
        "if shuffle_toggle:\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "# Get training/validation indices\n",
        "train_indices, test_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Generate samplers\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "test_sampler = SubsetRandomSampler(test_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "eKNkFIRY9Z7w"
      },
      "outputs": [],
      "source": [
        "# Generate data loaders\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
        "#kwargs = {'num_workers': 0} \n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, **kwargs)\n",
        "test_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=test_sampler, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QmA4XGfG-e-Z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "print(len(train_loader))\n",
        "print(len(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "mHy11ApKq3FM"
      },
      "outputs": [],
      "source": [
        "# MNIST Testing data\n",
        "\n",
        "mnist_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
        "\n",
        "train_dataset = MNIST(dataset_path, transform=mnist_transform, train=True, download=True)\n",
        "test_dataset  = MNIST(dataset_path, transform=mnist_transform, train=False, download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader  = DataLoader(dataset=test_dataset,  batch_size=batch_size, shuffle=False, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3aX2FK8rTHO"
      },
      "source": [
        "Implement Simple VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HONX58QMrSUl"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    A simple implementation of Gaussian MLP Encoder and Decoder\n",
        "\"\"\"\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.FC_input = nn.Linear(input_dim, hidden_dim)\n",
        "    self.FC_input2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.FC_mean  = nn.Linear(hidden_dim, latent_dim)\n",
        "    self.FC_var   = nn.Linear (hidden_dim, latent_dim)\n",
        "    \n",
        "    self.LeakyReLU = nn.LeakyReLU(0.2)\n",
        "    \n",
        "    self.training = True\n",
        "      \n",
        "  def forward(self, x):\n",
        "    h_       = self.LeakyReLU(self.FC_input(x))\n",
        "    h_       = self.LeakyReLU(self.FC_input2(h_))\n",
        "    mean     = self.FC_mean(h_)\n",
        "    log_var  = self.FC_var(h_)                     # encoder produces mean and log of variance \n",
        "                                                  #             (i.e., parameters of simple tractable normal distribution \"q\"\n",
        "    \n",
        "    return mean, log_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Xo-_3cU1rYqv"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, latent_dim, hidden_dim, output_dim):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.FC_hidden = nn.Linear(latent_dim, hidden_dim)\n",
        "    self.FC_hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.FC_output = nn.Linear(hidden_dim, output_dim)\n",
        "    \n",
        "    self.LeakyReLU = nn.LeakyReLU(0.2)\n",
        "      \n",
        "  def forward(self, x):\n",
        "    h = self.LeakyReLU(self.FC_hidden(x))\n",
        "    h = self.LeakyReLU(self.FC_hidden2(h))\n",
        "    \n",
        "    # originally torch.sigmoid, but output range incorrect\n",
        "    x_hat = torch.sigmoid(self.FC_output(h))\n",
        "    return x_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "t0hRtlO5ralJ"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, Encoder, Decoder):\n",
        "    super(Model, self).__init__()\n",
        "    self.Encoder = Encoder\n",
        "    self.Decoder = Decoder\n",
        "      \n",
        "  def reparameterization(self, mean, var):\n",
        "    epsilon = torch.randn_like(var).to(DEVICE)        # sampling epsilon        \n",
        "    z = mean + var*epsilon                          # reparameterization trick\n",
        "    return z\n",
        "      \n",
        "              \n",
        "  def forward(self, x):\n",
        "    # Generate mean, log var\n",
        "    mean, log_var = self.Encoder(x)\n",
        "\n",
        "    z = self.reparameterization(mean, torch.exp(0.5 * log_var)) # takes exponential function (log var -> var)\n",
        "    x_hat = self.Decoder(z)\n",
        "    \n",
        "    return x_hat, mean, log_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cDqjx8Pyrekx"
      },
      "outputs": [],
      "source": [
        "encoder = Encoder(input_dim=x_dim, hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
        "decoder = Decoder(latent_dim=latent_dim, hidden_dim = hidden_dim, output_dim = x_dim)\n",
        "\n",
        "model = Model(Encoder=encoder, Decoder=decoder).to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gg0P-A_LrhK5"
      },
      "outputs": [],
      "source": [
        "BCE_loss = nn.BCELoss()\n",
        "\n",
        "def loss_function(x, x_hat, mean, log_var):\n",
        "  reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')\n",
        "  KLD = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
        "\n",
        "  return reproduction_loss + KLD\n",
        "\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "for batch_idx, (x) in enumerate(train_loader):\n",
        "    print(\"Batch\",batch_idx)\n",
        "    print(x[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "dYM5WBzTriny"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training VAE...\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "shape '[5, 784]' is invalid for input of size 37570",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-22-30bf1eb71f3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: shape '[5, 784]' is invalid for input of size 37570"
          ]
        }
      ],
      "source": [
        "print(\"Start training VAE...\")\n",
        "model.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  overall_loss = 0\n",
        "  \n",
        "  for batch_idx, (x) in enumerate(train_loader):\n",
        "    x = x.view(batch_size, x_dim)\n",
        "    x = x.to(DEVICE)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    x_hat, mean, log_var = model(x)\n",
        "    loss = loss_function(x, x_hat, mean, log_var)\n",
        "    \n",
        "    overall_loss += loss.item()\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "      \n",
        "  print(\"\\tEpoch\", epoch + 1, \"complete!\", \"\\tAverage Loss: \", overall_loss / (batch_idx*batch_size))\n",
        "    \n",
        "print(\"Finished!!!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GjN2krOr0nI"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (x) in enumerate(tqdm(test_loader)):\n",
        "    x = x.view(batch_size, x_dim)\n",
        "    x = x.to(DEVICE)\n",
        "    \n",
        "    x_hat, _, _ = model(x)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsJCDz_Ywk9C"
      },
      "outputs": [],
      "source": [
        "#x[1] = x[1] * reduced_maximum\n",
        "print(x[0])\n",
        "\n",
        "plt.title('Original Spectra')\n",
        "plt.xlabel('Wavelength')\n",
        "plt.ylabel('Relative Flux')\n",
        "# 7514 data points for each spectra\n",
        "plt.plot(x[0].cpu().numpy())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcETlCUsOVOI"
      },
      "outputs": [],
      "source": [
        "#x_hat[1] = x_hat[1] * reduced_maximum\n",
        "\n",
        "print(x_hat[0])\n",
        "\n",
        "plt.title('Reconstructed Spectra')\n",
        "plt.xlabel('Wavelength')\n",
        "plt.ylabel('Relative Flux')\n",
        "# 7514 data points for each spectra\n",
        "plt.plot(x_hat[0].cpu().numpy())\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "vae_test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
